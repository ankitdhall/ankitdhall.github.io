<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>depth estimation | Ankit Dhall</title>
    <link>https://ankitdhall.github.io/tags/depth-estimation/</link>
      <atom:link href="https://ankitdhall.github.io/tags/depth-estimation/index.xml" rel="self" type="application/rss+xml" />
    <description>depth estimation</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>&amp;copy 2020</copyright><lastBuildDate>Mon, 06 Apr 2020 10:24:40 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>depth estimation</title>
      <link>https://ankitdhall.github.io/tags/depth-estimation/</link>
    </image>
    
    <item>
      <title>AMZ Driverless</title>
      <link>https://ankitdhall.github.io/project/keypoint-network-amz/</link>
      <pubDate>Mon, 06 Apr 2020 10:24:40 +0200</pubDate>
      <guid>https://ankitdhall.github.io/project/keypoint-network-amz/</guid>
      <description>&lt;h2 id=&#34;keypoint-network-for-monocular-pose-estimation&#34;&gt;Keypoint-Network for Monocular Pose Estimation&lt;/h2&gt;
&lt;p&gt;The work was done in collaboration with 
&lt;a href=&#34;https://vision.ee.ethz.ch/&#34; title=&#34;Computer Vision Lab, ETH Zurich&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CVL@ETH-Zurich&lt;/a&gt; with 
&lt;a href=&#34;http://www.vision.ee.ethz.ch/~daid/&#34; title=&#34;Dengxin Dai&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dengxin Dai&lt;/a&gt; and 
&lt;a href=&#34;https://scholar.google.ch/citations?user=TwMib_QAAAAJ&amp;amp;hl=en&amp;amp;oi=ao&#34; title=&#34;Prof. Luc van Gool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Luc van Gool&lt;/a&gt;. The official project page can be found 
&lt;a href=&#34;https://www.trace.ethz.ch/TrafficCone/&#34; title=&#34;Real-time 3D Traffic Cone Detection for Autonomous Driving&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;h1 id=&#34;amz-driverlesshttpdriverlessamzracingch-amz-driverless-homepage&#34;&gt;
&lt;a href=&#34;http://driverless.amzracing.ch/&#34; title=&#34;AMZ-Driverless&amp;#39; Homepage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AMZ-Driverless&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;I was officially involved in the 2018-2019 season as the Head of Perception with &lt;strong&gt;pilatus driverless&lt;/strong&gt;. The year before, I was worked on the computer vision pipeline, more specifically developed the monocular pipeline and the keypoint network.&lt;/p&gt;
&lt;h2 id=&#34;involvement&#34;&gt;Involvement&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;pilatus driverless&lt;/strong&gt;: Head of Perception [2018-2019]&lt;br&gt;
&lt;strong&gt;gotthard driverless&lt;/strong&gt;: Computer Vision [2017-2018]&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;driverless-cars-in-action&#34;&gt;Driverless cars in action&lt;/h2&gt;
&lt;h3 id=&#34;pilatus-driverless-fs-germany-2019&#34;&gt;pilatus driverless @FS Germany 2019&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://youtu.be/OX8RSyF9mnw?list=PLtuNXpGOPQ_b5fejuHQrdE8PcW5kJ31F7&amp;amp;t=10079&#34; title=&#34;Acceleration&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Acceleration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://youtu.be/gcnngFyWnFQ?list=PLtuNXpGOPQ_b5fejuHQrdE8PcW5kJ31F7&amp;amp;t=13068&#34; title=&#34;Trackdrive&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trackdrive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://youtu.be/sxqkt_ydOkY?list=PLtuNXpGOPQ_b5fejuHQrdE8PcW5kJ31F7&amp;amp;t=10749&#34; title=&#34;AutoX&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AutoX&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gotthard-driverless-fs-germany-2018&#34;&gt;gotthard driverless @FS Germany 2018&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://youtu.be/HegmIXASKow?t=11694&#34; title=&#34;Trackdrive&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trackdrive&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;acknowledgement&#34;&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;We would like to thank 
&lt;a href=&#34;http://amzracing.ch/&#34; title=&#34;AMZ&amp;#39;s Homepage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AMZ Racing&lt;/a&gt;, especially the 
&lt;a href=&#34;http://driverless.amzracing.ch/&#34; title=&#34;AMZ-Driverless&amp;#39; Homepage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Driverless&lt;/a&gt; team without whom this project would not have been possible. The work is also supported by Toyota Motor Europe via the project 
&lt;a href=&#34;https://www.trace.ethz.ch/&#34; title=&#34;Trace-Zurich&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TRACE-Zurich&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Real-time 3D Traffic Cone Detection for Autonomous Driving</title>
      <link>https://ankitdhall.github.io/publication/keypoint-network-amz/</link>
      <pubDate>Wed, 06 Feb 2019 10:24:27 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/keypoint-network-amz/</guid>
      <description>&lt;p&gt;Considerable progress has been made in semantic scene understanding of road scenes with monocular cameras. It is, however, mainly focused on certain specific classes such as cars, bicyclists and pedestrians. This work investigates traffic cones, an object category crucial for traffic control in the context of autonomous vehicles. 3D object detection using images from a monocular camera is intrinsically an ill-posed problem. In this work, we exploit the unique structure of traffic cones and propose a pipelined approach to solve this problem. Specifically, we first detect cones in images by a modified 2D object detector. Following which the keypoints on a traffic cone are recognized with the help of our deep structural regression network, here, the fact that the cross-ratio is projection invariant is leveraged for network regularization. Finally, the 3D position of cones is recovered via the classical Perspective n-Point algorithm using correspondences obtained from the keypoint regression. Extensive experiments show that our approach can accurately detect traffic cones and estimate their position in the 3D world in real time. The proposed method is also deployed on a real-time, autonomous system. It runs efficiently on the low-power Jetson TX2, providing accurate 3D position estimates, allowing a race-car to map and drive autonomously on an unseen track indicated by traffic cones. With the help of robust and accurate perception, our race-car won both Formula Student Competitions held in Italy and Germany in 2018, cruising at a top speed of 54 km/h on our driverless platform ``gotthard driverless&amp;rsquo;&amp;rsquo;
&lt;img src=&#34;FSG19_Trackdrive_D.gif&#34; alt=&#34;alt text&#34; title=&#34;&amp;lt;&amp;lt;gotthard driverless&amp;gt;&amp;gt; on the Trackdrive at Formula Student Germany 2018&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

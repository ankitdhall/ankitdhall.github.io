<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>thesis | Ankit Dhall</title>
    <link>https://ankitdhall.github.io/tags/thesis/</link>
      <atom:link href="https://ankitdhall.github.io/tags/thesis/index.xml" rel="self" type="application/rss+xml" />
    <description>thesis</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020 Ankit Dhall</copyright><lastBuildDate>Wed, 08 Apr 2020 11:49:06 +0200</lastBuildDate>
    <image>
      <url>https://ankitdhall.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>thesis</title>
      <link>https://ankitdhall.github.io/tags/thesis/</link>
    </image>
    
    <item>
      <title>Hierarchical Image Classification Using Entailment Cone Embeddings</title>
      <link>https://ankitdhall.github.io/publication/hierarchical-image-classification-using-entailment-cone-embeddings/</link>
      <pubDate>Wed, 08 Apr 2020 11:49:06 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/hierarchical-image-classification-using-entailment-cone-embeddings/</guid>
      <description>&lt;p&gt;Image classification has been studied extensively, but there has been limited work in using unconventional, external guidance other than traditional image-label pairs for training. We present a set of methods for leveraging information about the semantic hierarchy embedded in class labels. We first inject label-hierarchy knowledge into an arbitrary CNN-based classifier and empirically show that availability of such external semantic information in conjunction with the visual semantics from images boosts overall performance. Taking a step further in this direction, we model more explicitly the label-label and label-image interactions using order-preserving embeddings governed by both Euclidean and hyperbolic geometries, prevalent in natural language, and tailor them to hierarchical image classification and representation learning. We empirically validate all the models on the hierarchical ETHEC dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Representation Learning</title>
      <link>https://ankitdhall.github.io/project/learning-representations-for-images-with-hierarchical-labels/</link>
      <pubDate>Tue, 07 Apr 2020 18:31:49 +0200</pubDate>
      <guid>https://ankitdhall.github.io/project/learning-representations-for-images-with-hierarchical-labels/</guid>
      <description>&lt;h2 id=&#34;publications&#34;&gt;Publications&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://arxiv.org/abs/2004.00909&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning Representations for Images With Hierarchical Labels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://arxiv.org/abs/2004.03459&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hierarchical Image Classification Using Entailment Cone Embeddings&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;I worked on my Master thesis at 
&lt;a href=&#34;https://las.inf.ethz.ch/krausea&#34; title=&#34;Andreas Krause&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andreas Krause&amp;rsquo;s&lt;/a&gt; 
&lt;a href=&#34;https://las.inf.ethz.ch/&#34; title=&#34;Learning and Adaptive Systems Group, ETH Zurich&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning and Adaptive Systems Group@ETH-Zurich&lt;/a&gt; supervised by 
&lt;a href=&#34;https://las.inf.ethz.ch/people/anastasia-makarova&#34; title=&#34;Anastasia Makarova&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anastasia Makarova&lt;/a&gt;, 
&lt;a href=&#34;https://people.csail.mit.edu/oct/&#34; title=&#34;Octavian Eugen-Ganea&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Octavian Eugen-Ganea&lt;/a&gt; and 
&lt;a href=&#34;http://da.inf.ethz.ch/people/DarioPavllo/&#34; title=&#34;Dario Pavllo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dario Pavllo&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The project works on using external information in the form of leveraging hierarchy formed by labels to aid image classification. The work compares two different types of models: CNN-based models and Euclidean + non-Euclidean embedding-based models.&lt;/p&gt;
&lt;h3 id=&#34;cnn-based-models&#34;&gt;CNN-based models&lt;/h3&gt;
&lt;p&gt;Instead of proposing special modules, the CNN-based models exploit the hierarchy using loss functions that incorporate this hierarchical information in different degrees.&lt;/p&gt;
&lt;h3 id=&#34;euclidean-and-non-euclidean-embeddings&#34;&gt;Euclidean and Non-Euclidean embeddings&lt;/h3&gt;
&lt;p&gt;Euclidean and non-Euclidean embedding models are taken from natural language processing (NLP) where they are hugely prevalent. We propose to use these models for computer vision and images by learning representation in joint-embedding spaces for both concepts and images.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ec_2d_labels.png&#34; alt=&#34;alt text&#34; title=&#34;ETHEC dataset&#39;s Euclidean Cone embeddings in 2D&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;predicting-taxonomy-for-organisms&#34;&gt;Predicting Taxonomy for Organisms&lt;/h3&gt;
&lt;p&gt;One of the main applications of this work is to assist natural history collections, museums and organizations that preserve large numbers of historical and extant biodiversity specimens to digitize and organize their collections. Hobbyists create their personal collections most of which are eventually donated to public institutions. Before integration, these specimens need to be sorted taxonomically by specialists who have little time and are expensive. If this resource intensive task could be preceded by a pre-sorting procedure, for instance, where these specimens are categorized by unskilled labour based on their &lt;em&gt;family&lt;/em&gt;, &lt;em&gt;sub-family&lt;/em&gt;, &lt;em&gt;genus&lt;/em&gt;, and &lt;em&gt;species&lt;/em&gt; it would expedite and economize the process.&lt;/p&gt;
&lt;p&gt;Thanks to the 
&lt;a href=&#34;https://www.librarylab.ethz.ch/&#34; title=&#34;The ETH Library Lab&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The ETH Library Lab&lt;/a&gt; and Michael Greeff the research conducted on the thesis will be turned into classification app that can be used by hobbyists, collectors, and researchers alike to speed up and economize classification and segregation of entomological specimens. More information about the app will be made available soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Representations for Images With Hierarchical Labels</title>
      <link>https://ankitdhall.github.io/publication/learning-representations-for-images-with-hierarchical-labels/</link>
      <pubDate>Tue, 07 Apr 2020 15:45:29 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/learning-representations-for-images-with-hierarchical-labels/</guid>
      <description>&lt;p&gt;Image classification has been studied extensively but there has been limited work in the direction of using non-conventional, external guidance other than traditional image-label pairs to train such models. In this thesis we present a set of methods to leverage information about the semantic hierarchy induced by class labels. In the first part of the thesis, we inject label-hierarchy knowledge to an arbitrary classifier and empirically show that availability of such external semantic information in conjunction with the visual semantics from images boosts overall performance. Taking a step further in this direction, we model more explicitly the label-label and label-image interactions by using order-preserving embedding-based models, prevalent in natural language, and tailor them to the domain of computer vision to perform image classification. Although, contrasting in nature, both the CNN-classifiers injected with hierarchical information, and the embedding-based models outperform a hierarchy-agnostic model on the newly presented, real-world ETH Entomological Collection image dataset.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

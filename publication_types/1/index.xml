<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 | Ankit Dhall</title>
    <link>https://ankitdhall.github.io/publication_types/1/</link>
      <atom:link href="https://ankitdhall.github.io/publication_types/1/index.xml" rel="self" type="application/rss+xml" />
    <description>1</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020 Ankit Dhall</copyright><lastBuildDate>Wed, 08 Apr 2020 11:49:06 +0200</lastBuildDate>
    <image>
      <url>https://ankitdhall.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>1</title>
      <link>https://ankitdhall.github.io/publication_types/1/</link>
    </image>
    
    <item>
      <title>Hierarchical Image Classification Using Entailment Cone Embeddings</title>
      <link>https://ankitdhall.github.io/publication/hierarchical-image-classification-using-entailment-cone-embeddings/</link>
      <pubDate>Wed, 08 Apr 2020 11:49:06 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/hierarchical-image-classification-using-entailment-cone-embeddings/</guid>
      <description>&lt;p&gt;Image classification has been studied extensively, but there has been limited work in using unconventional, external guidance other than traditional image-label pairs for training. We present a set of methods for leveraging information about the semantic hierarchy embedded in class labels. We first inject label-hierarchy knowledge into an arbitrary CNN-based classifier and empirically show that availability of such external semantic information in conjunction with the visual semantics from images boosts overall performance. Taking a step further in this direction, we model more explicitly the label-label and label-image interactions using order-preserving embeddings governed by both Euclidean and hyperbolic geometries, prevalent in natural language, and tailor them to hierarchical image classification and representation learning. We empirically validate all the models on the hierarchical ETHEC dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Real-time 3D Traffic Cone Detection for Autonomous Driving</title>
      <link>https://ankitdhall.github.io/publication/keypoint-network-amz/</link>
      <pubDate>Wed, 06 Feb 2019 10:24:27 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/keypoint-network-amz/</guid>
      <description>&lt;p&gt;Considerable progress has been made in semantic scene understanding of road scenes with monocular cameras. It is, however, mainly focused on certain specific classes such as cars, bicyclists and pedestrians. This work investigates traffic cones, an object category crucial for traffic control in the context of autonomous vehicles. 3D object detection using images from a monocular camera is intrinsically an ill-posed problem. In this work, we exploit the unique structure of traffic cones and propose a pipelined approach to solve this problem. Specifically, we first detect cones in images by a modified 2D object detector. Following which the keypoints on a traffic cone are recognized with the help of our deep structural regression network, here, the fact that the cross-ratio is projection invariant is leveraged for network regularization. Finally, the 3D position of cones is recovered via the classical Perspective n-Point algorithm using correspondences obtained from the keypoint regression. Extensive experiments show that our approach can accurately detect traffic cones and estimate their position in the 3D world in real time. The proposed method is also deployed on a real-time, autonomous system. It runs efficiently on the low-power Jetson TX2, providing accurate 3D position estimates, allowing a race-car to map and drive autonomously on an unseen track indicated by traffic cones. With the help of robust and accurate perception, our race-car won both Formula Student Competitions held in Italy and Germany in 2018, cruising at a top speed of 54 km/h on our driverless platform ``gotthard driverless&amp;rsquo;&amp;rsquo;
&lt;img src=&#34;FSG19_Trackdrive_D.gif&#34; alt=&#34;alt text&#34; title=&#34;&amp;lt;&amp;lt;gotthard driverless&amp;gt;&amp;gt; on the Trackdrive at Formula Student Germany 2018&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AdapNet: Adaptive Semantic Segmentation in Adverse Environmental Conditions</title>
      <link>https://ankitdhall.github.io/publication/adapnet/</link>
      <pubDate>Wed, 05 Apr 2017 23:25:48 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/adapnet/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://deepscene.cs.uni-freiburg.de/&#34; target=&#34;_blank&#34;&gt;project page + web demo&lt;/a&gt; |
videos &lt;a href=&#34;https://www.youtube.com/watch?v=E6gij6IS8n0&#34; title=&#34;AdapNet: Adaptive Semantic Segmentation in Adverse Environmental Conditions&#34; target=&#34;_blank&#34;&gt;[1]&lt;/a&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=7teAwVMTCho&#34; title=&#34;cityscapes demo&#34; target=&#34;_blank&#34;&gt;[2]&lt;/a&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=cV-k0gkVfuY&#34; title=&#34;autonomous navigation experiments&#34; target=&#34;_blank&#34;&gt;[3]&lt;/a&gt; &lt;p&gt;&lt;/p&gt;
Robust scene understanding of outdoor environments using passive optical sensors is an onerous and essential task for autonomous navigation. The problem is heavily characterized by changing environmental conditions throughout the day and across seasons. Robots should be equipped with models that are impervious to these factors in order to be operable and more importantly to ensure safety in the real-world. In this paper, we propose a novel semantic segmentation architecture and the convoluted mixture of deep experts (CMoDE) fusion technique that enables a multi-stream deep neural network to learn features from complementary modalities and spectra, each of which are specialized in a subset of the input space. We present results from experimentation on three publicly available datasets that contain diverse conditions including rain, summer, winter, dusk, fall, night and sunset, and show that our approach exceeds the state-of-the-art. In addition, we evaluate the performance of autonomously traversing several kilometers of a forested environment (see the video links for more info) using only the segmentation for perception.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convoluted Mixture of Deep Experts for Robust Semantic Segmentation</title>
      <link>https://ankitdhall.github.io/publication/cmode/</link>
      <pubDate>Tue, 05 Apr 2016 23:41:00 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/cmode/</guid>
      <description>&lt;p&gt;In this paper, we propose Convoluted Mixture of Deep Experts (CMoDE) model that enables a multi-stream deep neural network architecture to learn features from complementary modalities and spectra that are resilient to commonly observed environmental disturbances. Some of these disturbances include shadows, snow, rain and glare which vary depending with season and time of the day. Our model first adaptively weighs features from each of the individual experts and then further learns fused representations that are robust to these disturbances. We comprehensively evaluate the CMoDE model against several other existing fusion approaches and show that our proposed model exceeds the state-of-the-art.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Optimizing Human-Machine Task Assignments</title>
      <link>https://ankitdhall.github.io/publication/optimizing-human-machine-task-assignment/</link>
      <pubDate>Sun, 05 Apr 2015 23:48:26 +0200</pubDate>
      <guid>https://ankitdhall.github.io/publication/optimizing-human-machine-task-assignment/</guid>
      <description>&lt;p&gt;When crowdsourcing systems are used in combination with machine inference systems in the real world, they benefit the most when the machine system is deeply integrated with the crowd workers. However, if researchers wish to integrate the crowd with &amp;ldquo;off-the-shelf&amp;rdquo; machine classifiers, this deep integration is not always possible. This work explores two strategies to increase accuracy and decrease cost under this setting. First, we show that reordering tasks presented to the human can create a significant accuracy improvement. Further, we show that greedily choosing parameters to maximize machine accuracy is sub-optimal, and joint optimization of the combined system improves performance.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>

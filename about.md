---
layout: page
title: About
permalink: /about/
---

I am **Ankit Dhall**, and I have recently completed my undergraduate studies in Computer Science at VIT University. My interests lie at the intersection of Computer Vision and Robotics.

In 2015 had the opportunity of working under [Prof. James Davis](https://users.soe.ucsc.edu/~davis/) and [Rajan Vaish](https://stanford.edu/~rvaish/), where we worked towards improving crowdsourcing by [prosposing a strategy](http://arxiv.org/abs/1509.07543) that integrates the machine system with the crowd-sourcing platform. We show how providing images in a particular order to the crowd can provide a speed-up of more than 2x.

In the summer of 2016, I spent time as a research intern at [Prof. Wolfram Burgard's](http://www2.informatik.uni-freiburg.de/~burgard/) [Autonomous Intelligent Systems (AIS)](http://ais.informatik.uni-freiburg.de/index_en.php) research group in the lovely town of Freiburg, Germany. I worked on the [AdapNet](http://ais.informatik.uni-freiburg.de/publications/papers/valada17icra.pdf) that intelligently fuses RGB and depth images to provide robust semantic segmentation for both indoors as well as outdoors and employs our novel self-adapting deep learning architecture, [Convoluted Mixture of Deep Experts (CMoDE)](http://ais.informatik.uni-freiburg.de/publications/papers/valada16irosws.pdf). We used this to run autonomous driving experiments for several kilometers in the forest.

For my bachelor thesis I worked as a research intern at [IIIT-Hyderabad](https://www.iiit.ac.in/) in [Prof. Madhava Krishna's](http://faculty.iiit.ac.in/~mkrishna/index.html) lab at the [Robotics Research Center (RRC)](http://robotics.iiit.ac.in/). My work involved finding extrinsic calibration parameters, in the form of a rotation and translation between a LiDAR and a camera. Previous methods work well with high density LiDARs but are troublesome when used with a VLP-16, a low-end LiDAR. After trying various approaches and not getting desired results, a novel pipeline and experimental was designed that gave extremely accurate estimates. Taking, this forward, we show how this method can be used to even calibrate cameras with no overlapping field-of-view. We further demonstrate the accuracy of the method by fusing point clouds from stereo cameras which align almost perfectly with our estimated values of the rigid-body transformation.  

You can read more about these projects on my [research page](/publications/). Here is my [resume](/assets/AnkitDhall_resume.pdf).


